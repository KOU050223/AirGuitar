# AirGuitar

エアギターをするよ

# 1. 全体アーキテクチャの概要
### PCを中核としたシステム:
- PCは主にユーザーによる音の設定、セッション管理、高品質な音響処理（エフェクト・ミキシングなど）を担当します。
- また、各デバイスからの入力データを統合し、リアルタイムで音再生の制御を行います。

#### スマートフォン（左手デバイス）:
- プログレッシブWebアプリ（PWA）として実装し、PCから受信した音設定情報を表示。
- タッチ操作やスライダーで補助的な入力を行い、PCとの通信は初期はWebSocketで実現します。

### 右手デバイス:
- BLE対応のハードウェアで、加速度センサー等により振動やモーションを検知。
- Web Bluetooth APIを用いて、スマートフォン（PWA）と直接通信し、加速度データを送信します。

# 2. 各デバイスの役割と連携
## PC側:

### 音の設定:
- ユーザーはPCの管理画面で、サウンド設定（サンプル音、パワーコード、エフェクトなど）を細かく行う。
### 入力統合: 
- スマートフォン（左手）と右手デバイスから送られる入力データ（タッチ操作、加速度データ）を統合し、音再生のタイミングを判断。
### 音響処理: 
高度な音響合成・エフェクト処理を行い、再生品質を向上させる。
## スマートフォン（PWA）:

### 設定情報の受信:
- PC側から配信される音設定情報を受け取り、UI上に反映。
### ユーザー入力:
- タッチ操作やスライダーによる操作を通じ、再生トリガーや補助的な操作を提供。
### BLE接続: 
- Web Bluetooth APIにより、右手デバイスと接続し、リアルタイムに加速度データを受信。
## 右手デバイス:

### モーション入力: 
- 加速度センサーでユーザーの振動や動作を検知し、必要な入力データを生成。
### データ送信: 
- BLEを介して、スマートフォン（PWA）にデータを送信する。

# 3. 通信プロトコルと将来的な拡張
## 初期実装:

### PCとスマートフォン間:
- 同一LAN内での低レイテンシな双方向通信としてWebSocketを利用。
### スマートフォンと右手デバイス間:
- Web Bluetooth APIを活用し、BLE経由で直接接続。

## 将来的な拡張:

- PCとスマートフォン間の通信について、余裕が出た段階でWebRTCへの移行を検討。
→ これにより、より低遅延で柔軟なP2P通信環境を実現できる可能性がある。

# 4. プロジェクト管理・開発体制
## コードベースの管理:

- 複数の技術スタック（TypeScript/JavaScript、ファームウェア）を扱うため、適切なリポジトリ分割やMonorepoの運用を検討。
- TSとJSの混在については、tsconfig.jsonのallowJs設定やディレクトリ分けで対応する。

## チーム分担:

- PC側管理（音響処理・設定UI）担当、スマートフォン（PWA・BLE接続）担当、右手デバイス（ファームウェア・センサーデータ送信）担当に分け、各分野の専門性を活かす。

## まとめ
- PCで音の設定・管理を行い、PCが中心となって音響処理を担当する。
- スマートフォンはPWAとして、PCから設定情報を受信し、ユーザー入力（タッチ操作等）やBLE接続による右手デバイスからのデータを中継。
- 右手デバイスはBLE経由で加速度センサーデータをスマートフォンへ送信し、音再生のトリガーとなる。
- 初期はPCとスマートフォン間はWebSocket通信を利用し、後にWebRTCへ移行する計画。